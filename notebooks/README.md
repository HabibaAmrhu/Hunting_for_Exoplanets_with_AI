# Exoplanet Detection Pipeline - Notebook Suite

This directory contains a comprehensive suite of Jupyter notebooks demonstrating our physics-informed exoplanet detection pipeline. Each notebook focuses on specific aspects of the machine learning workflow, from data preparation to deployment.

## üìö Notebook Overview

### 1. **00_data_prep_kepler.ipynb** - Data Preparation
- **Purpose**: Download and preprocess Kepler KOI data
- **Key Features**:
  - NASA Exoplanet Archive API integration
  - Automated data quality validation
  - Preprocessing pipeline with phase-folding
  - Sample size management for different environments

### 2. **01_train_baseline.ipynb** - Baseline Model Training
- **Purpose**: Train and evaluate baseline CNN models
- **Key Features**:
  - Physics-informed synthetic transit generation
  - Real vs synthetic data comparison
  - Comprehensive performance evaluation
  - Model checkpointing and saving

### 3. **02_augmentation_and_cv.ipynb** - Augmentation & Cross-Validation
- **Purpose**: Advanced augmentation techniques and robust validation
- **Key Features**:
  - Traditional vs physics-informed augmentation comparison
  - Star-level stratified cross-validation
  - Ablation studies on augmentation components
  - Synthetic transit validation and quality assessment

### 4. **03_train_ensemble.ipynb** - Ensemble Training
- **Purpose**: Multi-architecture ensemble methods
- **Key Features**:
  - CNN, LSTM, and Transformer model combination
  - Uncertainty quantification with Monte Carlo Dropout
  - Weighted voting strategies
  - Ensemble calibration analysis

### 5. **04_evaluate_and_explain.ipynb** - Evaluation & Explainability
- **Purpose**: Comprehensive model evaluation and interpretation
- **Key Features**:
  - Integrated Gradients implementation for time series
  - Model comparison across all architectures
  - Error analysis and failure mode identification
  - Calibration assessment and reliability metrics### 6. *
*05_deploy_streamlit.ipynb** - Deployment Demonstration
- **Purpose**: Deploy and test the Streamlit web application
- **Key Features**:
  - Multi-environment deployment (Local, Colab, Kaggle)
  - Automated dependency installation
  - Application health testing
  - Comprehensive troubleshooting guide

## üöÄ Quick Start Guide

### Prerequisites
```bash
# Install required packages
pip install torch torchvision scikit-learn pandas numpy matplotlib seaborn plotly streamlit jupyter

# Clone/download the repository
# Ensure you have the complete src/ directory structure
```

### Running the Notebooks

1. **Start with Data Preparation**:
   ```bash
   jupyter notebook 00_data_prep_kepler.ipynb
   ```

2. **Train Baseline Models**:
   ```bash
   jupyter notebook 01_train_baseline.ipynb
   ```

3. **Explore Advanced Techniques**:
   ```bash
   # Run in order for best results
   jupyter notebook 02_augmentation_and_cv.ipynb
   jupyter notebook 03_train_ensemble.ipynb
   jupyter notebook 04_evaluate_and_explain.ipynb
   ```

4. **Deploy the Application**:
   ```bash
   jupyter notebook 05_deploy_streamlit.ipynb
   ```

## üî¨ Key Innovations Demonstrated

### Physics-Informed Synthetic Transits
- **Mandel-Agol transit model** with quadratic limb darkening
- **Realistic parameter distributions** from Kepler survey statistics
- **Stellar-specific limb darkening** based on effective temperature
- **Noise modeling** matching observational characteristics

### Advanced Model Architectures
- **1D CNN** with dual-channel input (raw + phase-folded)
- **BiLSTM with attention** for temporal modeling
- **Transformer** with 1D positional encoding
- **Ensemble methods** with uncertainty quantification

### Robust Evaluation Framework
- **Star-level cross-validation** to prevent data leakage
- **Comprehensive metrics** (F1, ROC-AUC, PR-AUC, calibration)
- **Explainability** with Integrated Gradients
- **Error analysis** and failure mode identification

## üìä Expected Results

### Performance Improvements
- **Baseline CNN**: ~0.85 F1-score on validation set
- **With Synthetic Transits**: ~0.92 F1-score (+8% improvement)
- **Ensemble Methods**: ~0.94 F1-score (+11% improvement)
- **Cross-validation**: Robust performance across different star populations

### Key Findings
1. **Physics-informed augmentation** significantly outperforms traditional methods
2. **Ensemble approaches** provide better calibration and uncertainty estimates
3. **Phase-folding** enhances transit signal detection
4. **Star-level CV** reveals more realistic performance estimates

## üõ†Ô∏è Environment Compatibility

### Local Development
- **Requirements**: Python 3.7+, 8GB RAM recommended
- **GPU**: Optional but recommended for faster training
- **Storage**: ~2GB for full dataset and models

### Google Colab
- **Free Tier**: Sufficient for demonstration with sample data
- **Pro/Pro+**: Recommended for full dataset training
- **Special Features**: Automatic ngrok tunneling for Streamlit

### Kaggle Notebooks
- **GPU**: P100 or T4 recommended
- **Internet**: Required for data download
- **Storage**: Persistent datasets supported

## üîß Troubleshooting

### Common Issues
1. **Memory Errors**: Reduce batch size or use CPU-only mode
2. **Import Errors**: Ensure src/ directory is in Python path
3. **Data Download**: Check internet connection and API limits
4. **Model Loading**: Verify checkpoint files exist and are compatible

### Performance Optimization
- Use **mixed precision training** for faster GPU training
- Enable **gradient checkpointing** for memory efficiency
- Use **data parallel** training for multiple GPUs
- Implement **early stopping** to prevent overfitting

## üìà Extending the Pipeline

### Adding New Models
1. Implement model class in `src/models/`
2. Add to ensemble framework
3. Update evaluation notebooks
4. Test with cross-validation

### Custom Augmentations
1. Create augmentation class in `src/data/augmentation.py`
2. Add to pipeline configurations
3. Evaluate in augmentation notebook
4. Compare with physics-informed methods

### New Datasets
1. Implement downloader in `src/data/`
2. Update preprocessing pipeline
3. Validate with existing models
4. Document performance differences

## üìö References and Citations

- **Mandel & Agol (2002)**: Transit light curve modeling
- **Kepler Mission**: NASA Exoplanet Archive data
- **Integrated Gradients**: Sundararajan et al. (2017)
- **Ensemble Methods**: Breiman (2001), Dietterich (2000)

## ü§ù Contributing

To contribute to this notebook suite:
1. Follow the established code structure
2. Add comprehensive documentation
3. Include performance benchmarks
4. Test across multiple environments
5. Update this README with new features

---

**Note**: This notebook suite represents a complete, production-ready exoplanet detection pipeline with state-of-the-art techniques and comprehensive evaluation frameworks.